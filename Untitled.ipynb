{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:44:03.912067Z",
     "start_time": "2019-11-11T23:44:03.896115Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import glob\n",
    "import pickle\n",
    "import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T00:06:51.236333Z",
     "start_time": "2019-11-12T00:06:51.224368Z"
    }
   },
   "outputs": [],
   "source": [
    "U_psi = tf.ones((5,5))\n",
    "U_h = tf.constant(np.arange(25).reshape((5,5)),dtype=tf.float32)\n",
    "\n",
    "li_U_psi = tf.split(U_psi,5)\n",
    "li_U_h = tf.split(U_h, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T00:07:11.786017Z",
     "start_time": "2019-11-12T00:07:11.774042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=1207, shape=(1, 5), dtype=float32, numpy=array([[1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " <tf.Tensor: id=1208, shape=(1, 5), dtype=float32, numpy=array([[1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " <tf.Tensor: id=1209, shape=(1, 5), dtype=float32, numpy=array([[1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " <tf.Tensor: id=1210, shape=(1, 5), dtype=float32, numpy=array([[1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " <tf.Tensor: id=1211, shape=(1, 5), dtype=float32, numpy=array([[1., 1., 1., 1., 1.]], dtype=float32)>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_U_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T00:38:04.068167Z",
     "start_time": "2019-11-12T00:38:04.060179Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def _func1(x):\n",
    "    #print(x)\n",
    "    z = x[0] + x[1]\n",
    "    return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T00:38:05.454693Z",
     "start_time": "2019-11-12T00:38:05.410751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1552, shape=(5, 2, 5), dtype=float32, numpy=\n",
       "array([[[ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 0.,  1.,  2.,  3.,  4.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 5.,  6.,  7.,  8.,  9.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.],\n",
       "        [10., 11., 12., 13., 14.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.],\n",
       "        [15., 16., 17., 18., 19.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.],\n",
       "        [20., 21., 22., 23., 24.]]], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.concat([li_U_psi, li_U_h], axis=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T00:38:06.818638Z",
     "start_time": "2019-11-12T00:38:06.798667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1643, shape=(5, 5), dtype=float32, numpy=\n",
       "array([[ 1.,  2.,  3.,  4.,  5.],\n",
       "       [ 6.,  7.,  8.,  9., 10.],\n",
       "       [11., 12., 13., 14., 15.],\n",
       "       [16., 17., 18., 19., 20.],\n",
       "       [21., 22., 23., 24., 25.]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.map_fn( _func1, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T00:20:00.093679Z",
     "start_time": "2019-11-12T00:20:00.080711Z"
    }
   },
   "outputs": [],
   "source": [
    "b =tfd.MultivariateNormalFullCovariance(loc=[[1,1.,10]]*3,covariance_matrix= tf.constant([[1,2.,3]]*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T00:20:01.925892Z",
     "start_time": "2019-11-12T00:20:01.904960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1548, shape=(1, 3, 3), dtype=float32, numpy=\n",
       "array([[[0.6483379 , 2.0202856 , 9.411564  ],\n",
       "        [1.494083  , 0.44273818, 9.016466  ],\n",
       "        [0.44021446, 0.2870041 , 8.763435  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T22:52:42.874951Z",
     "start_time": "2019-10-29T22:52:42.862983Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Creating T1\n",
    "_array = np.arange(9).reshape(3,3)\n",
    "input_dims = [5,5]\n",
    "output_dims = [ 15 , 15 ]\n",
    "\n",
    "inp_dim_h = input_dims[0]\n",
    "inp_dim_w = input_dims[1]\n",
    "\n",
    "outp_dim_h = output_dims[0]\n",
    "outp_dim_w = output_dims[1]\n",
    "\n",
    "upsample_h = outp_dim_h - inp_dim_h #amount to expand in height dimension\n",
    "upsample_w = outp_dim_w - inp_dim_w\n",
    "\n",
    "upsample_h_inner = outp_dim_h - (upsample_h % (inp_dim_h-1) ) #amount to expand in height dimension, by inner padding\n",
    "upsample_w_inner = outp_dim_w - (upsample_w % (inp_dim_w-1) ) #amount to expand in width dimension, w/ inner padding\n",
    "\n",
    "stride_h = int( (upsample_h_inner-inp_dim_h)/(inp_dim_h-1) )\n",
    "stride_w = int( (upsample_w_inner-inp_dim_w)/(inp_dim_w-1) )\n",
    "\n",
    "# Creating transformation matrices\n",
    "T_1 = np.zeros( (upsample_h_inner, inp_dim_h) )\n",
    "T_2 = np.zeros( (inp_dim_w, upsample_w_inner ) )\n",
    "\n",
    "d1 = np.einsum('ii->i', T_1[ ::stride_h+1,:] ) \n",
    "d1 += 1\n",
    "\n",
    "d2 = np.einsum('ii->i', T_2[ :, ::stride_w+1] )\n",
    "d2 += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T22:59:44.265124Z",
     "start_time": "2019-10-29T22:59:44.256148Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T22:50:26.751215Z",
     "start_time": "2019-10-29T22:50:26.743236Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_image = np.ones((1,5,5,1))\n",
    "_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T22:36:14.747474Z",
     "start_time": "2019-10-29T22:36:14.739500Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_temp = np.matmul( T_1, _image)\n",
    "_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T22:52:07.371604Z",
     "start_time": "2019-10-29T22:52:07.360625Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.einsum('ij,jk->ik', T_1, _image[0,:,:,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T23:01:22.334960Z",
     "start_time": "2019-10-29T23:01:22.329981Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_images1 = np.einsum('ij,hjkl->hikl', T_1, _image )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T16:04:33.006109Z",
     "start_time": "2019-10-31T16:04:32.995138Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# data pipeline hdr images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:14.538432Z",
     "start_time": "2019-11-06T13:00:14.511508Z"
    },
    "code_folding": [
     16
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_num_parallel_calls =tf.data.experimental.AUTOTUNE \n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# region elevation\n",
    "_path = \"Data/Preprocessed/elevation.pkl\" #TODO:(akanni-ade) change to value passed in via a h-parameters dictionary\n",
    "with open(_path,\"rb\") as f: #TODO:(akanni-ade) change to value passed in via a h-parameters dictionary\n",
    "    arr_elev = pickle.load(f)\n",
    "    \n",
    "arr_elev = arr_elev[::4, ::4]  #shape( 156,352 ) #16kmby16km\n",
    "    #creating layered representation of 16kmby16km arr_elev such that it is same shape as 64kmby64km precip\n",
    "        ##take cell i,j in 2d array. each cell in the square matrix around cell i,j is stacked underneath i,j. \n",
    "        ## The square has dimensions (rel to i,j): 2 to the right, 2 down, 1 left, 1 right\n",
    "        ## This achieves a dimension reduction of 4\n",
    "MAX_ELEV = 2500 #TODO: (akanni-ade) Find actual max elev\n",
    "arr_elev = arr_elev / MAX_ELEV \n",
    "\n",
    "def stacked_reshape( arr, first_centre, downscale_x, downscale_y, batch_size = BATCH_SIZE ):\n",
    "    \"\"\"\n",
    "        This produces a list of tiled arrays. This ensures higher resolution data _arr has the same shape as lower resolution data, ignoring a depth dimension\n",
    "        i.e.\n",
    "\n",
    "        The array is stacked to create a new dimension (axis=-1). The stack happens on the following cells:\n",
    "            first centre (i,j)\n",
    "            (i+n*downscale_x, j+n*downscale_y ) for integer n\n",
    "\n",
    "        :param arr: 2D array\n",
    "        :first centre: tuple (i,j) indexing where the upperleft most position to stack on\n",
    "\n",
    "        returns arr_stacked\n",
    "    \"\"\"\n",
    "    new_depth = downscale_x * downscale_y\n",
    "    dim_x, dim_y = arr.shape\n",
    "    li_arr = []\n",
    "\n",
    "    idxs_x = list( range(downscale_x) )\n",
    "    idxs_y = list( range(downscale_y) )\n",
    "    starting_idxs = list( itertools.product( idxs_x, idxs_y ) )\n",
    "\n",
    "    for x,y in starting_idxs:\n",
    "        end_x = dim_x - ( downscale_x-first_centre[0] - x) \n",
    "        end_y = dim_y - ( downscale_y-first_centre[1] - y)\n",
    "        arr_cropped = arr[ x:end_x, y:end_y ]\n",
    "\n",
    "        li_arr.append(arr_cropped)\n",
    "\n",
    "    li_tnsr = [ tf.expand_dims(_arr[::downscale_x, ::downscale_y],0) for _arr in li_arr ]\n",
    "    li_tnsr_elev =  [ tf.tile(_tnsr,[BATCH_SIZE,1,1]) for _tnsr in li_elev_tiled ]\n",
    "    tnsr_elev_tiled = tf.stack(li_tnsr_elev, axis=-1)\n",
    "    \n",
    "    #arr_stacked = np.stack( li_arr, axis=-1 )\n",
    "    #arr_stacked = arr_stacked[::downscale_x, ::downscale_y] \n",
    "\n",
    "    return tnsr_elev_tiled\n",
    "\n",
    "\n",
    "tnsr_elev_tiled = stacked_reshape( arr_elev, (1,1), 4, 4  ) # list[ (1, 39, 88), (1, 39, 88), ... ] #16kmby16km "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:16.905509Z",
     "start_time": "2019-11-06T13:00:16.880595Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 39, 88, 16])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnsr_elev_tiled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:25.946308Z",
     "start_time": "2019-11-06T13:00:25.392467Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# region precip, features, targets\n",
    "_dir_precip = \"./Data/PRISM/daily_precip\"\n",
    "file_paths_bil = list( glob.glob(_dir_precip+\"/*/*.bil\" ) )\n",
    "file_paths_bil.sort(reverse=False)\n",
    "\n",
    "ds_fns_precip = tf.data.Dataset.from_tensor_slices(file_paths_bil)\n",
    "\n",
    "ds_precip_imgs = ds_fns_precip.map( lambda fn: tf.py_function(utility.read_prism_precip,[fn], [tf.float32] ), num_parallel_calls=_num_parallel_calls ) #shape(bs, 621, 1405) #4km by 4km\n",
    "\n",
    "ds_precip_imgs = ds_precip_imgs.batch(BATCH_SIZE,drop_remainder=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:49:14.478418Z",
     "start_time": "2019-11-06T11:49:14.422572Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "next(iter(ds_precip_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:33.859083Z",
     "start_time": "2019-11-06T13:00:33.846123Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def features_labels_mker( arr_images, tnsr_elev_tiled=tnsr_elev_tiled ):\n",
    "    \"\"\"Produces the precipitation features and the target for training\n",
    "    shape(bs, rows, cols)\n",
    "    \"\"\"\n",
    "    #standardisation\n",
    "    MAX_RAIN = 200 #TODO:(akanni-ade) Find actual max rain\n",
    "    arr_images = arr_images / MAX_RAIN \n",
    "\n",
    "    #features\n",
    "    precip_feat = reduce_res( arr_images, 16, 16 ) #shape(bs, 621/16, 1405/16) (bs, 39, 88)  64km by 64km\n",
    "\n",
    "\n",
    "    feat = tf.concat( [tf.expand_dims(precip_feat,-1),tnsr_elev_tiled], axis=-1 ) #shape(bs, 39, 88, 17)  64km by 64km\n",
    "\n",
    "    #targets        \n",
    "    precip_tar = reduce_res( arr_images, 4, 4)   #shape( bs, 621/4, 1405/4 ) (bs,156,352) 16km by 16km\n",
    "\n",
    "    #TODO(akanni-ade): consider applying cropping to remove large parts that are just water \n",
    "        # #cropping\n",
    "        # precip_tar = precip_tar[:, : , : ]\n",
    "        # feat = feat[:, :, :, :]\n",
    "\n",
    "    return feat, precip_tar\n",
    "\n",
    "def reduce_res(arr_imgs, x_axis, y_axis):\n",
    "    arr_imgs_red = arr_imgs[:,::x_axis, ::y_axis]\n",
    "    return arr_imgs_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:42.151451Z",
     "start_time": "2019-11-06T13:00:41.900057Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_precip_feat_tar = ds_precip_imgs.map( features_labels_mker, num_parallel_calls=_num_parallel_calls ) #shape( (bs, 39, 88, 17 ) (bs,156,352) )\n",
    "ds_precip_feat_tar = ds_precip_feat_tar\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:44.454584Z",
     "start_time": "2019-11-06T13:00:44.295762Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feat_tar = next(iter(ds_precip_feat_tar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:49.128702Z",
     "start_time": "2019-11-06T13:00:49.109758Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=268, shape=(1, 39, 88, 17), dtype=float32, numpy=\n",
       " array([[[[      nan,       nan,       nan, ..., 2.168e-01, 2.000e-02,\n",
       "                 nan],\n",
       "          [      nan, 9.680e-02, 9.240e-02, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan, 4.536e-01, 5.992e-01, ...,       nan,       nan,\n",
       "           5.800e-02],\n",
       "          ...,\n",
       "          [      nan, 1.548e-01, 1.460e-01, ..., 8.320e-02, 5.960e-02,\n",
       "           9.080e-02],\n",
       "          [      nan, 1.184e-01, 1.272e-01, ..., 6.240e-02,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan]],\n",
       " \n",
       "         [[      nan, 1.840e-01, 1.280e-02, ..., 7.520e-02, 1.216e-01,\n",
       "           2.964e-01],\n",
       "          [      nan, 1.428e-01, 1.736e-01, ..., 1.320e-01, 3.068e-01,\n",
       "           2.016e-01],\n",
       "          [      nan,       nan,       nan, ..., 7.760e-02, 2.800e-03,\n",
       "                 nan],\n",
       "          ...,\n",
       "          [      nan, 1.200e-02,       nan, ...,       nan,       nan,\n",
       "           1.000e-02],\n",
       "          [      nan,       nan,       nan, ..., 5.560e-02, 1.300e-01,\n",
       "           1.412e-01],\n",
       "          [      nan,       nan,       nan, ..., 2.040e-01, 1.268e-01,\n",
       "           1.596e-01]],\n",
       " \n",
       "         [[      nan,       nan,       nan, ...,       nan, 4.000e-03,\n",
       "           1.016e-01],\n",
       "          [      nan, 2.424e-01, 3.232e-01, ..., 9.720e-02, 2.352e-01,\n",
       "           7.040e-02],\n",
       "          [      nan, 1.704e-01, 4.920e-02, ..., 2.768e-01, 1.008e-01,\n",
       "           4.840e-02],\n",
       "          ...,\n",
       "          [      nan, 2.240e-02, 1.600e-03, ..., 1.264e-01, 1.208e-01,\n",
       "           1.308e-01],\n",
       "          [      nan, 7.800e-02, 1.216e-01, ..., 1.512e-01, 1.168e-01,\n",
       "           8.080e-02],\n",
       "          [      nan, 1.388e-01, 2.048e-01, ..., 3.520e-02, 5.040e-02,\n",
       "           4.000e-04]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          ...,\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan]],\n",
       " \n",
       "         [[      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          ...,\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan]],\n",
       " \n",
       "         [[      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          ...,\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=269, shape=(1, 156, 352), dtype=float32, numpy=\n",
       " array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sampling from distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:53:00.080275Z",
     "start_time": "2019-11-06T15:53:00.072300Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_loc = [1,2,3,4,5,6]\n",
    "_scale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:53:01.172675Z",
     "start_time": "2019-11-06T15:53:01.163706Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dist = tfp.distributions.Normal(loc=_loc, scale=_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:53:02.448200Z",
     "start_time": "2019-11-06T15:53:02.436233Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=365, shape=(1, 6), dtype=float32, numpy=\n",
       "array([[0.773104 , 3.1078181, 2.7096798, 5.4086576, 5.9865575, 5.486517 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:53:05.741807Z",
     "start_time": "2019-11-06T15:53:05.711884Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=375, shape=(6,), dtype=float32, numpy=\n",
       "array([-0.9189385, -0.9189385, -0.9189385, -0.9189385, -0.9189385,\n",
       "       -0.9189385], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = [1,2,3,4,5,6]\n",
    "dist.log_prob( [1,2,3,4,5,6] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# LinearOperators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T22:37:21.639557Z",
     "start_time": "2019-11-11T22:37:21.610606Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b = tf.Variable(12.0)\n",
    "a = tf.random.uniform((3,3)) + b\n",
    "a_lin = tf.linalg.LinearOperatorFullMatrix([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T22:37:21.660475Z",
     "start_time": "2019-11-11T22:37:21.644516Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=17, shape=(1, 3, 3), dtype=float32, numpy=\n",
       "array([[[12.988561 , 12.930893 , 12.824854 ],\n",
       "        [12.093805 , 12.7253475, 12.5665865],\n",
       "        [12.56972  , 12.185729 , 12.826218 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_lin.to_dense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T22:38:08.300169Z",
     "start_time": "2019-11-11T22:38:08.283218Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=22, shape=(1, 3, 1), dtype=float32, numpy=\n",
       " array([[[12.988561],\n",
       "         [12.093805],\n",
       "         [12.56972 ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=23, shape=(1, 3, 1), dtype=float32, numpy=\n",
       " array([[[12.930893 ],\n",
       "         [12.7253475],\n",
       "         [12.185729 ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=24, shape=(1, 3, 1), dtype=float32, numpy=\n",
       " array([[[12.824854 ],\n",
       "         [12.5665865],\n",
       "         [12.826218 ]]], dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.split(a_lin.to_dense(),3 ,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T20:38:42.271232Z",
     "start_time": "2019-11-10T20:38:42.256280Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c = tf.linalg.LinearOperatorDiag([1,2,3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T20:44:25.432204Z",
     "start_time": "2019-11-10T20:44:25.413253Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = tf.ones_like(a)\n",
    "e  = a_lin.add_to_tensor(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T20:44:28.955245Z",
     "start_time": "2019-11-10T20:44:28.941285Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=115, shape=(1, 3, 3), dtype=float32, numpy=\n",
       "array([[[13.376913 , 13.902765 , 13.1032095],\n",
       "        [13.280859 , 13.346211 , 13.340479 ],\n",
       "        [13.765435 , 13.790724 , 13.878635 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T20:52:16.111453Z",
     "start_time": "2019-11-10T20:52:16.096493Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f = tf.linalg.LinearOperatorKronecker([a_lin,c]).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-10T20:55:13.633Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfd.MultivariateNormalFullCovariance(loc=0 , covariance_matrix=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T02:13:39.664723Z",
     "start_time": "2019-11-07T02:13:39.640753Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=446, shape=(4750,), dtype=float32, numpy=\n",
       "array([ 2.7652726 ,  2.3383532 ,  1.237061  , ..., -0.7985437 ,\n",
       "       -1.6175447 ,  0.07468408], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal(tf.reshape(4750, [-1]),1,1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T02:09:40.751092Z",
     "start_time": "2019-11-07T02:09:40.707149Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(4750,) dtype=float32, numpy=\n",
       "array([-0.3507694 ,  0.31105453, -1.2595296 , ...,  0.44483012,\n",
       "        2.9954767 ,  1.0497129 ], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T02:12:13.628526Z",
     "start_time": "2019-11-07T02:12:13.600523Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=427, shape=(4500,), dtype=float32, numpy=\n",
       "array([-0.6947933 ,  0.56837213,  1.0733191 , ..., -0.0614842 ,\n",
       "       -0.05265053, -2.462337  ], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal( tf.reshape(tf.constant(4500),[-1]), mean=0, stddev=1 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
