{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T18:18:09.931739Z",
     "start_time": "2020-01-08T18:18:09.925376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T18:28:49.980153Z",
     "start_time": "2020-01-08T18:28:49.973732Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=3)\n",
    "#np.core.arrayprint._line_width = 500\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.5g\" % x))\n",
    "\n",
    "import itertools\n",
    "import glob\n",
    "import pickle\n",
    "import utility\n",
    "import util_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T22:52:42.874951Z",
     "start_time": "2019-10-29T22:52:42.862983Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Creating T1\n",
    "_array = np.arange(9).reshape(3,3)\n",
    "input_dims = [5,5]\n",
    "output_dims = [ 15 , 15 ]\n",
    "\n",
    "inp_dim_h = input_dims[0]\n",
    "inp_dim_w = input_dims[1]\n",
    "\n",
    "outp_dim_h = output_dims[0]\n",
    "outp_dim_w = output_dims[1]\n",
    "\n",
    "upsample_h = outp_dim_h - inp_dim_h #amount to expand in height dimension\n",
    "upsample_w = outp_dim_w - inp_dim_w\n",
    "\n",
    "upsample_h_inner = outp_dim_h - (upsample_h % (inp_dim_h-1) ) #amount to expand in height dimension, by inner padding\n",
    "upsample_w_inner = outp_dim_w - (upsample_w % (inp_dim_w-1) ) #amount to expand in width dimension, w/ inner padding\n",
    "\n",
    "stride_h = int( (upsample_h_inner-inp_dim_h)/(inp_dim_h-1) )\n",
    "stride_w = int( (upsample_w_inner-inp_dim_w)/(inp_dim_w-1) )\n",
    "\n",
    "# Creating transformation matrices\n",
    "T_1 = np.zeros( (upsample_h_inner, inp_dim_h) )\n",
    "T_2 = np.zeros( (inp_dim_w, upsample_w_inner ) )\n",
    "\n",
    "d1 = np.einsum('ii->i', T_1[ ::stride_h+1,:] ) \n",
    "d1 += 1\n",
    "\n",
    "d2 = np.einsum('ii->i', T_2[ :, ::stride_w+1] )\n",
    "d2 += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T22:59:44.265124Z",
     "start_time": "2019-10-29T22:59:44.256148Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T22:50:26.751215Z",
     "start_time": "2019-10-29T22:50:26.743236Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_image = np.ones((1,5,5,1))\n",
    "_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T22:36:14.747474Z",
     "start_time": "2019-10-29T22:36:14.739500Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_temp = np.matmul( T_1, _image)\n",
    "_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T22:52:07.371604Z",
     "start_time": "2019-10-29T22:52:07.360625Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.einsum('ij,jk->ik', T_1, _image[0,:,:,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T23:01:22.334960Z",
     "start_time": "2019-10-29T23:01:22.329981Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_images1 = np.einsum('ij,hjkl->hikl', T_1, _image )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T16:04:33.006109Z",
     "start_time": "2019-10-31T16:04:32.995138Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# data pipeline hdr images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:14.538432Z",
     "start_time": "2019-11-06T13:00:14.511508Z"
    },
    "code_folding": [
     16
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_num_parallel_calls =tf.data.experimental.AUTOTUNE \n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# region elevation\n",
    "_path = \"Data/Preprocessed/elevation.pkl\" #TODO:(akanni-ade) change to value passed in via a h-parameters dictionary\n",
    "with open(_path,\"rb\") as f: #TODO:(akanni-ade) change to value passed in via a h-parameters dictionary\n",
    "    arr_elev = pickle.load(f)\n",
    "    \n",
    "arr_elev = arr_elev[::4, ::4]  #shape( 156,352 ) #16kmby16km\n",
    "    #creating layered representation of 16kmby16km arr_elev such that it is same shape as 64kmby64km precip\n",
    "        ##take cell i,j in 2d array. each cell in the square matrix around cell i,j is stacked underneath i,j. \n",
    "        ## The square has dimensions (rel to i,j): 2 to the right, 2 down, 1 left, 1 right\n",
    "        ## This achieves a dimension reduction of 4\n",
    "MAX_ELEV = 2500 #TODO: (akanni-ade) Find actual max elev\n",
    "arr_elev = arr_elev / MAX_ELEV \n",
    "\n",
    "def stacked_reshape( arr, first_centre, downscale_x, downscale_y, batch_size = BATCH_SIZE ):\n",
    "    \"\"\"\n",
    "        This produces a list of tiled arrays. This ensures higher resolution data _arr has the same shape as lower resolution data, ignoring a depth dimension\n",
    "        i.e.\n",
    "\n",
    "        The array is stacked to create a new dimension (axis=-1). The stack happens on the following cells:\n",
    "            first centre (i,j)\n",
    "            (i+n*downscale_x, j+n*downscale_y ) for integer n\n",
    "\n",
    "        :param arr: 2D array\n",
    "        :first centre: tuple (i,j) indexing where the upperleft most position to stack on\n",
    "\n",
    "        returns arr_stacked\n",
    "    \"\"\"\n",
    "    new_depth = downscale_x * downscale_y\n",
    "    dim_x, dim_y = arr.shape\n",
    "    li_arr = []\n",
    "\n",
    "    idxs_x = list( range(downscale_x) )\n",
    "    idxs_y = list( range(downscale_y) )\n",
    "    starting_idxs = list( itertools.product( idxs_x, idxs_y ) )\n",
    "\n",
    "    for x,y in starting_idxs:\n",
    "        end_x = dim_x - ( downscale_x-first_centre[0] - x) \n",
    "        end_y = dim_y - ( downscale_y-first_centre[1] - y)\n",
    "        arr_cropped = arr[ x:end_x, y:end_y ]\n",
    "\n",
    "        li_arr.append(arr_cropped)\n",
    "\n",
    "    li_tnsr = [ tf.expand_dims(_arr[::downscale_x, ::downscale_y],0) for _arr in li_arr ]\n",
    "    li_tnsr_elev =  [ tf.tile(_tnsr,[BATCH_SIZE,1,1]) for _tnsr in li_tnsr ]\n",
    "    tnsr_elev_tiled = tf.stack(li_tnsr_elev, axis=-1)\n",
    "    \n",
    "    #arr_stacked = np.stack( li_arr, axis=-1 )\n",
    "    #arr_stacked = arr_stacked[::downscale_x, ::downscale_y] \n",
    "\n",
    "    return tnsr_elev_tiled\n",
    "\n",
    "\n",
    "tnsr_elev_tiled = stacked_reshape( arr_elev, (1,1), 4, 4  ) # list[ (1, 39, 88), (1, 39, 88), ... ] #16kmby16km "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 39, 88, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnsr_elev_tiled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:25.946308Z",
     "start_time": "2019-11-06T13:00:25.392467Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# region precip, features, targets\n",
    "_num_parallel_calls=1\n",
    "BATCH_SIZE=1\n",
    "_dir_precip = \"./Data/PRISM/daily_precip\"\n",
    "file_paths_bil = list( glob.glob(_dir_precip+\"/*/*.bil\" ) )\n",
    "file_paths_bil.sort(reverse=False)\n",
    "\n",
    "ds_fns_precip = tf.data.Dataset.from_tensor_slices(file_paths_bil)\n",
    "\n",
    "ds_precip_imgs = ds_fns_precip.map( lambda fn: tf.py_function(utility.read_prism_precip,[fn], [tf.float32] ), num_parallel_calls=_num_parallel_calls ) #shape(bs, 621, 1405) #4km by 4km\n",
    "\n",
    "ds_precip_imgs = ds_precip_imgs.batch(BATCH_SIZE,drop_remainder=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:49:14.478418Z",
     "start_time": "2019-11-06T11:49:14.422572Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=31, shape=(1, 621, 1405), dtype=float32, numpy=\n",
       " array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)>,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ds_precip_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:33.859083Z",
     "start_time": "2019-11-06T13:00:33.846123Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def features_labels_mker( arr_images, tnsr_elev_tiled=tnsr_elev_tiled ):\n",
    "    \"\"\"Produces the precipitation features and the target for training\n",
    "    shape(bs, rows, cols)\n",
    "    \"\"\"\n",
    "    #standardisation\n",
    "    MAX_RAIN = 200 #TODO:(akanni-ade) Find actual max rain\n",
    "    arr_images = arr_images / MAX_RAIN \n",
    "\n",
    "    #features\n",
    "    precip_feat = reduce_res( arr_images, 16, 16 ) #shape(bs, 621/16, 1405/16) (bs, 39, 88)  64km by 64km\n",
    "\n",
    "\n",
    "    feat = tf.concat( [tf.expand_dims(precip_feat,-1),tnsr_elev_tiled], axis=-1 ) #shape(bs, 39, 88, 17)  64km by 64km\n",
    "\n",
    "    #targets        \n",
    "    precip_tar = reduce_res( arr_images, 4, 4)   #shape( bs, 621/4, 1405/4 ) (bs,156,352) 16km by 16km\n",
    "\n",
    "    #TODO(akanni-ade): consider applying cropping to remove large parts that are just water \n",
    "        # #cropping\n",
    "        # precip_tar = precip_tar[:, : , : ]\n",
    "        # feat = feat[:, :, :, :]\n",
    "\n",
    "    return feat, precip_tar\n",
    "\n",
    "def reduce_res(arr_imgs, x_axis, y_axis):\n",
    "    arr_imgs_red = arr_imgs[:,::x_axis, ::y_axis]\n",
    "    return arr_imgs_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:42.151451Z",
     "start_time": "2019-11-06T13:00:41.900057Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_precip_feat_tar = ds_precip_imgs.map( features_labels_mker, num_parallel_calls=_num_parallel_calls ) #shape( (bs, 39, 88, 17 ) (bs,156,352) )\n",
    "ds_precip_feat_tar = ds_precip_feat_tar\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:44.454584Z",
     "start_time": "2019-11-06T13:00:44.295762Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feat_tar = next(iter(ds_precip_feat_tar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:00:49.128702Z",
     "start_time": "2019-11-06T13:00:49.109758Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=193, shape=(1, 39, 88, 17), dtype=float32, numpy=\n",
       " array([[[[      nan,       nan,       nan, ..., 2.168e-01, 2.000e-02,\n",
       "                 nan],\n",
       "          [      nan, 9.680e-02, 9.240e-02, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan, 4.536e-01, 5.992e-01, ...,       nan,       nan,\n",
       "           5.800e-02],\n",
       "          ...,\n",
       "          [      nan, 1.548e-01, 1.460e-01, ..., 8.320e-02, 5.960e-02,\n",
       "           9.080e-02],\n",
       "          [      nan, 1.184e-01, 1.272e-01, ..., 6.240e-02,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan]],\n",
       " \n",
       "         [[      nan, 1.840e-01, 1.280e-02, ..., 7.520e-02, 1.216e-01,\n",
       "           2.964e-01],\n",
       "          [      nan, 1.428e-01, 1.736e-01, ..., 1.320e-01, 3.068e-01,\n",
       "           2.016e-01],\n",
       "          [      nan,       nan,       nan, ..., 7.760e-02, 2.800e-03,\n",
       "                 nan],\n",
       "          ...,\n",
       "          [      nan, 1.200e-02,       nan, ...,       nan,       nan,\n",
       "           1.000e-02],\n",
       "          [      nan,       nan,       nan, ..., 5.560e-02, 1.300e-01,\n",
       "           1.412e-01],\n",
       "          [      nan,       nan,       nan, ..., 2.040e-01, 1.268e-01,\n",
       "           1.596e-01]],\n",
       " \n",
       "         [[      nan,       nan,       nan, ...,       nan, 4.000e-03,\n",
       "           1.016e-01],\n",
       "          [      nan, 2.424e-01, 3.232e-01, ..., 9.720e-02, 2.352e-01,\n",
       "           7.040e-02],\n",
       "          [      nan, 1.704e-01, 4.920e-02, ..., 2.768e-01, 1.008e-01,\n",
       "           4.840e-02],\n",
       "          ...,\n",
       "          [      nan, 2.240e-02, 1.600e-03, ..., 1.264e-01, 1.208e-01,\n",
       "           1.308e-01],\n",
       "          [      nan, 7.800e-02, 1.216e-01, ..., 1.512e-01, 1.168e-01,\n",
       "           8.080e-02],\n",
       "          [      nan, 1.388e-01, 2.048e-01, ..., 3.520e-02, 5.040e-02,\n",
       "           4.000e-04]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          ...,\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan]],\n",
       " \n",
       "         [[      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          ...,\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan]],\n",
       " \n",
       "         [[      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          ...,\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan],\n",
       "          [      nan,       nan,       nan, ...,       nan,       nan,\n",
       "                 nan]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=194, shape=(1, 156, 352), dtype=float32, numpy=\n",
       " array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Creating Boolean mask to ignore the water Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bool_mask = np.logical_not( np.isnan(tf.squeeze(feat_tar[1]) ) )  #True means it should not be masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'156_352'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'_'.join( map( str, bool_mask.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(bool_mask,open(\"Images/water_mask_{}.dat\".format('_'.join( map( str, bool_mask.shape ) )),\"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sampling from distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:53:00.080275Z",
     "start_time": "2019-11-06T15:53:00.072300Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_loc = [1,2,3,4,5,6]\n",
    "_scale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:53:01.172675Z",
     "start_time": "2019-11-06T15:53:01.163706Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dist = tfp.distributions.Normal(loc=_loc, scale=_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:53:02.448200Z",
     "start_time": "2019-11-06T15:53:02.436233Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dist.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:53:05.741807Z",
     "start_time": "2019-11-06T15:53:05.711884Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target = [1,2,3,4,5,6]\n",
    "dist.log_prob( [1,2,3,4,5,6] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# LinearOperators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T22:37:21.639557Z",
     "start_time": "2019-11-11T22:37:21.610606Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b = tf.Variable(12.0)\n",
    "a = tf.random.uniform((3,3)) + b\n",
    "a_lin = tf.linalg.LinearOperatorFullMatrix([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T22:37:21.660475Z",
     "start_time": "2019-11-11T22:37:21.644516Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_lin.to_dense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T22:38:08.300169Z",
     "start_time": "2019-11-11T22:38:08.283218Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.split(a_lin.to_dense(),3 ,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T20:38:42.271232Z",
     "start_time": "2019-11-10T20:38:42.256280Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c = tf.linalg.LinearOperatorDiag([1,2,3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T20:44:25.432204Z",
     "start_time": "2019-11-10T20:44:25.413253Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = tf.ones_like(a)\n",
    "e  = a_lin.add_to_tensor(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T20:44:28.955245Z",
     "start_time": "2019-11-10T20:44:28.941285Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T20:52:16.111453Z",
     "start_time": "2019-11-10T20:52:16.096493Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f = tf.linalg.LinearOperatorKronecker([a_lin,c]).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-10T20:55:13.633Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfd.MultivariateNormalFullCovariance(loc=0 , covariance_matrix=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T02:13:39.664723Z",
     "start_time": "2019-11-07T02:13:39.640753Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = tf.random.normal(tf.reshape(4750, [-1]),1,1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T02:09:40.751092Z",
     "start_time": "2019-11-07T02:09:40.707149Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.Variable(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T02:12:13.628526Z",
     "start_time": "2019-11-07T02:12:13.600523Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.random.normal( tf.reshape(tf.constant(4500),[-1]), mean=0, stddev=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.linspace(88,352,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T18:17:04.163261Z",
     "start_time": "2020-01-08T18:17:04.153623Z"
    }
   },
   "source": [
    "# checking quantiles of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T18:19:34.110589Z",
     "start_time": "2020-01-08T18:19:34.105822Z"
    }
   },
   "outputs": [],
   "source": [
    "_path_pred_eval = _path_pred = \"./Output/{}/{}/EvaluatedPredictions\".format(\"DeepSD\", 3)\n",
    "gen_data_eval_preds = util_predict.load_predictions_gen(_path_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T18:20:09.695790Z",
     "start_time": "2020-01-08T18:20:09.537513Z"
    }
   },
   "outputs": [],
   "source": [
    "datum = next(gen_data_eval_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T18:20:54.096523Z",
     "start_time": "2020-01-08T18:20:54.091956Z"
    }
   },
   "outputs": [],
   "source": [
    "(np_rmse, np_bias, np_lower_bands, np_upper_bands, true_in_pred_range) = datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T18:29:34.905569Z",
     "start_time": "2020-01-08T18:29:34.902388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 156, 352)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T18:32:42.495150Z",
     "start_time": "2020-01-08T18:32:42.490909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 -200 2.0723 -200 -200]]\n",
      "\n",
      " [[2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723]\n",
      " [2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 2.0723 -200 2.0723 -200 -200]]\n"
     ]
    }
   ],
   "source": [
    "idx=2\n",
    "x_s, x_e = 100, 120\n",
    "y_s, y_e = 200, 220\n",
    "print(np_lower_bands[idx,x_s:x_e,y_s:y_e])\n",
    "print(\"\\n\",np_upper_bands[idx,x_s:x_e,y_s:y_e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T22:09:03.977772Z",
     "start_time": "2020-01-08T22:09:03.840575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are weights empty after restoring from checkpoint? False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import hparameters\n",
    "\n",
    "s_dir = utility.get_script_directory(sys.argv[0])\n",
    "\n",
    "#args_dict = utility.parse_arguments(s_dir)\n",
    "\n",
    "test_params = hparameters.test_hparameters(**{'script_dir':'/home/u1862646/ATI/BNN'})\n",
    "\n",
    "#stacked DeepSd methodology\n",
    "li_input_output_dims = [ {\"input_dims\": [39, 88 ], \"output_dims\": [98, 220 ] , 'var_model_type':'guassian_factorized' } ,\n",
    "             {\"input_dims\": [98, 220 ] , \"output_dims\": [ 156, 352 ] , 'conv1_inp_channels':1, 'var_model_type':'guassian_factorized' }  ]\n",
    "\n",
    "model_params = [ hparameters.model_deepsd_hparameters(**_dict) for _dict in li_input_output_dims  ]\n",
    "model_params = [ mp() for mp in model_params]\n",
    "\n",
    "model, checkpoint_code = util_predict.load_model(test_params(), model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T22:10:07.590749Z",
     "start_time": "2020-01-08T22:10:07.587495Z"
    }
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "qmeans = []\n",
    "qstds = []\n",
    "for i, layer in enumerate(model.layers):\n",
    "    try:\n",
    "        q = layer.kernel_posterior\n",
    "    except AttributeError:\n",
    "        continue\n",
    "    names.append(\"Layer {}\".format(i))\n",
    "    qmeans.append(q.mean())\n",
    "    qstds.append(q.stddev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T22:10:48.715002Z",
     "start_time": "2020-01-08T22:10:48.713001Z"
    }
   },
   "outputs": [],
   "source": [
    "a = model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T22:14:39.527342Z",
     "start_time": "2020-01-08T22:14:39.524087Z"
    }
   },
   "outputs": [],
   "source": [
    "a."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
