{"model_version": "1", "model_name": "THST", "model_type_settings": {"stochastic": false, "Deformable_Conv": true, "var_model_type": "Deterministic", "distr_type": "None", "discrete_continuous": false}, "encoder_params": {"encoder_layers": 5, "attn_layers": 4, "CLSTMs_params": [{"filters": 2, "kernel_size": [2, 2], "padding": "same", "return_sequences": true, "dropout": 0.05, "recurrent_dropout": 0.05, "stateful": true}, {"filters": 1, "kernel_size": [2, 2], "padding": "same", "return_sequences": true, "dropout": 0.05, "recurrent_dropout": 0.05, "stateful": true}, {"filters": 1, "kernel_size": [2, 2], "padding": "same", "return_sequences": true, "dropout": 0.05, "recurrent_dropout": 0.05, "stateful": true}, {"filters": 1, "kernel_size": [2, 2], "padding": "same", "return_sequences": true, "dropout": 0.05, "recurrent_dropout": 0.05, "stateful": true}, {"filters": 1, "kernel_size": [2, 2], "padding": "same", "return_sequences": true, "dropout": 0.05, "recurrent_dropout": 0.05, "stateful": true}], "ATTN_params": [{"bias": null, "total_key_depth": 165, "total_value_depth": 165, "output_depth": 165, "num_heads": 1, "dropout_rate": 0.05, "attention_type": "dot_product", "transform_value_antecedent": false, "transform_output": false}, {"bias": null, "total_key_depth": 82, "total_value_depth": 82, "output_depth": 82, "num_heads": 1, "dropout_rate": 0.05, "attention_type": "dot_product", "transform_value_antecedent": false, "transform_output": false}, {"bias": null, "total_key_depth": 82, "total_value_depth": 82, "output_depth": 82, "num_heads": 1, "dropout_rate": 0.05, "attention_type": "dot_product", "transform_value_antecedent": false, "transform_output": false}, {"bias": null, "total_key_depth": 82, "total_value_depth": 82, "output_depth": 82, "num_heads": 1, "dropout_rate": 0.05, "attention_type": "dot_product", "transform_value_antecedent": false, "transform_output": false}], "ATTN_DOWNSCALING_params_enc": {"vector_k_downscale_factor": 2, "vector_v_downscale_factor": 1, "kq_downscale_stride": [1, 13, 13], "kq_downscale_kernelshape": [1, 13, 13]}, "seq_len_factor_reduction": [4, 2, 2, 2], "num_of_splits": [16, 8, 4, 2], "dropout": 0.05}, "decoder_params": {"decoder_layers": 3, "CLSTMs_params": [{"filters": 2, "kernel_size": [2, 2], "padding": "same", "return_sequences": true, "dropout": 0.05, "gates_version": 2, "recurrent_dropout": 0.05, "stateful": true}, {"filters": 1, "kernel_size": [2, 2], "padding": "same", "return_sequences": true, "dropout": 0.05, "gates_version": 2, "recurrent_dropout": 0.05, "stateful": true}, {"filters": 1, "kernel_size": [2, 2], "padding": "same", "return_sequences": true, "dropout": 0.05, "gates_version": 2, "recurrent_dropout": 0.05, "stateful": true}], "seq_len_factor_reduction": [2, 2, 2], "num_of_splits": [8, 4, 2], "dropout": 0.05}, "output_layer_params": [{"filters": 3, "kernel_size": [2, 2], "padding": "same", "activation": "relu"}, {"filters": 1, "kernel_size": [2, 2], "padding": "same", "activation": "relu"}], "data_pipeline_params": {"lookback_feature": 64, "lookback_target": 16, "target_to_feature_time_ratio": 4}, "rec_adam_params": {"learning_rate": 0.0002, "warmup_proportion": 0.6, "min_lr": 0.0001, "beta_1": 0.9, "beta_2": 1.0, "epsilon": 1e-05}, "lookahead_params": {"sync_period": 3, "slow_step_size": 0.6}, "gradients_clip_norm": 200}